# üîß –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ RAG Platform

## üéØ –í–≤–µ–¥–µ–Ω–∏–µ

–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ RAG Platform! –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤, DevOps –∏–Ω–∂–µ–Ω–µ—Ä–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ, –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã.

## üìñ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã](#-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-—Å–∏—Å—Ç–µ–º—ã)
2. [‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ](#-—É—Å—Ç–∞–Ω–æ–≤–∫–∞-–∏-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ)
3. [üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã](#-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è-—Å–∏—Å—Ç–µ–º—ã)
4. [üë• –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏](#-—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏)
5. [üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞](#-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-–∏-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
6. [üõ°Ô∏è –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å](#-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
7. [üöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è](#-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å-–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
8. [üîÑ –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ](#-—Ä–µ–∑–µ—Ä–≤–Ω–æ–µ-–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ)
9. [üÜò –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫](#-–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞-–∏-—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ-–Ω–µ–ø–æ–ª–∞–¥–æ–∫)

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

```mermaid
graph TB
    subgraph "Frontend Layer"
        ST[Streamlit App<br/>Port: 8502]
        NG[Nginx Proxy<br/>Port: 80/443]
    end
    
    subgraph "Application Layer"
        API[FastAPI Server<br/>Port: 8081]
        AF[Airflow<br/>Port: 8080]
        SP[Superset<br/>Port: 8090]
    end
    
    subgraph "AI/ML Layer"
        OL[Ollama LLM<br/>Port: 11434]
        EMB[Embeddings Service]
        RAG[RAG Pipeline]
    end
    
    subgraph "Data Layer"
        PG[(PostgreSQL + pgvector<br/>Port: 5432)]
        RD[(Redis Cache<br/>Port: 6379)]
        CH[(ClickHouse Analytics<br/>Port: 8123)]
    end
    
    NG --> ST
    NG --> API
    NG --> SP
    NG --> AF
    
    ST --> API
    API --> OL
    API --> PG
    API --> RD
    API --> CH
    
    AF --> PG
    AF --> RD
    SP --> PG
    
    OL --> EMB
    EMB --> RAG
    RAG --> PG
```

### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –í–µ—Ä—Å–∏—è | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|-----------|------------|--------|------------|
| **Frontend** | Streamlit | 1.28+ | –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è |
| **API** | FastAPI | 0.104+ | RESTful API —Å–µ—Ä–≤–µ—Ä |
| **Database** | PostgreSQL + pgvector | 15+ | –û—Å–Ω–æ–≤–Ω–∞—è –ë–î –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ |
| **Cache** | Redis | 7+ | –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—á–µ—Ä–µ–¥–∏ |
| **Analytics** | ClickHouse | 23+ | –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ë–î –¥–ª—è –º–µ—Ç—Ä–∏–∫ |
| **LLM** | Ollama | Latest | –õ–æ–∫–∞–ª—å–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ |
| **Orchestration** | Apache Airflow | 2.7+ | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏ ETL |
| **Visualization** | Apache Superset | 3+ | –î–∞—à–±–æ—Ä–¥—ã –∏ –æ—Ç—á–µ—Ç—ã |
| **Proxy** | Nginx | 1.24+ | –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ |
| **Container** | Docker | 24+ | –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è |
| **Orchestration** | Kubernetes | 1.28+ | –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ |

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º

#### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Development)
- **CPU**: 4 —è–¥—Ä–∞
- **RAM**: 8 GB
- **Storage**: 50 GB SSD
- **Network**: 100 Mbps

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Production)
- **CPU**: 16 —è–¥–µ—Ä
- **RAM**: 64 GB
- **Storage**: 1 TB NVMe SSD
- **Network**: 1 Gbps
- **GPU**: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è AI

#### Enterprise —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- **CPU**: 32+ —è–¥–µ—Ä
- **RAM**: 128+ GB
- **Storage**: 10+ TB —Å —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–µ–π
- **Network**: 10 Gbps
- **High Availability**: –ö–ª–∞—Å—Ç–µ—Ä –∏–∑ 3+ –Ω–æ–¥

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ (Docker Compose)

#### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/rag-platform/rag-platform.git
cd rag-platform

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
cp infra/compose/env.example infra/compose/.env.local

# –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
nano infra/compose/.env.local
```

#### 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è .env.local
```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
ENVIRONMENT=production
COMPOSE_PROJECT_NAME=rag-platform

# –ü–æ—Ä—Ç—ã —Å–µ—Ä–≤–∏—Å–æ–≤
STREAMLIT_PORT=8502
API_PORT=8081
SUPERSET_PORT=8090
AIRFLOW_PORT=8080
POSTGRES_PORT=5432
REDIS_PORT=6379
CLICKHOUSE_PORT=8123
OLLAMA_PORT=11434

# –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
POSTGRES_USER=rag_user
POSTGRES_PASSWORD=secure_password_2024!
POSTGRES_DB=rag_db

# –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
JWT_SECRET_KEY=$(openssl rand -hex 64)
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
REDIS_TTL=3600
CACHE_TTL=1800

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
LOG_LEVEL=INFO
LOG_FORMAT=json

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
METRICS_ENABLED=true
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

# AI/ML –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
EMBEDDING_MODEL=bge-m3
LLM_MODEL=llama2-7b
OLLAMA_MODELS=llama2,bge-m3,nomic-embed-text

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
MAX_WORKERS=4
MAX_CONNECTIONS=100
UPLOAD_MAX_SIZE=100MB
```

#### 3. –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã
```bash
# –ü–æ–ª–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
cd infra/compose
docker compose up -d

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
docker compose ps

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
docker compose logs -f api
```

### Kubernetes —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

#### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ namespace
kubectl create namespace rag-platform

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤
kubectl create secret generic rag-platform-secrets \
  --namespace=rag-platform \
  --from-literal=jwt-secret-key=$(openssl rand -hex 64) \
  --from-literal=postgres-password=$(openssl rand -base64 32) \
  --from-literal=redis-password=$(openssl rand -base64 32)
```

#### 2. Helm —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
```bash
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Helm —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
helm dependency update infra/helm/rag-platform

# –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
helm install rag-platform infra/helm/rag-platform \
  --namespace rag-platform \
  --values infra/helm/rag-platform/values.yaml \
  --wait --timeout 15m
```

#### 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
```bash
# –°—Ç–∞—Ç—É—Å –ø–æ–¥–æ–≤
kubectl get pods -n rag-platform

# –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤
kubectl get svc -n rag-platform

# –õ–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
kubectl logs -f deployment/rag-platform-api -n rag-platform

# Health check
kubectl port-forward svc/rag-platform-api 8081:8081 -n rag-platform &
curl http://localhost:8081/health
```

### Production —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

#### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
```bash
# AWS EKS –∫–ª–∞—Å—Ç–µ—Ä
eksctl create cluster \
  --name rag-platform-prod \
  --version 1.28 \
  --region us-east-1 \
  --nodegroup-name workers \
  --node-type m5.2xlarge \
  --nodes 3 \
  --nodes-min 3 \
  --nodes-max 10 \
  --managed

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/aws/deploy.yaml
```

#### 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è production values
```yaml
# production-values.yaml
global:
  environment: production
  imageTag: "v1.0.0"
  domain: rag-platform.com

api:
  replicas: 3
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

postgresql:
  primary:
    persistence:
      size: 500Gi
      storageClass: gp3
  readReplicas:
    replicaCount: 2

redis:
  cluster:
    enabled: true
    nodes: 6

monitoring:
  enabled: true
  prometheus:
    enabled: true
  grafana:
    enabled: true

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "1000"
  tls:
    - secretName: rag-platform-tls
      hosts:
        - rag-platform.com
```

#### 3. Blue-Green —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
```bash
# –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
#!/bin/bash
set -e

NAMESPACE="rag-platform-production"
RELEASE_NAME="rag-platform"
NEW_VERSION=$1

if [ -z "$NEW_VERSION" ]; then
  echo "Usage: $0 <version>"
  exit 1
fi

echo "üöÄ Starting Blue-Green deployment for version $NEW_VERSION"

# 1. Deploy Green version
echo "üì¶ Deploying Green version..."
helm upgrade --install ${RELEASE_NAME}-green infra/helm/rag-platform \
  --namespace $NAMESPACE \
  --values production-values.yaml \
  --set global.imageTag=$NEW_VERSION \
  --set nameOverride="green" \
  --wait --timeout 15m

# 2. Health check
echo "üîç Running health checks..."
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=rag-platform,version=green \
  -n $NAMESPACE --timeout=300s

# 3. Smoke tests
echo "üí® Running smoke tests..."
kubectl run smoke-test --rm -i --image=curlimages/curl:latest --restart=Never -- \
  curl -f http://rag-platform-api-green.$NAMESPACE.svc.cluster.local:8081/health

# 4. Switch traffic
echo "üîÑ Switching traffic to Green..."
kubectl patch service rag-platform-api -n $NAMESPACE \
  -p '{"spec":{"selector":{"version":"green"}}}'

# 5. Wait and cleanup
echo "‚è∞ Waiting 5 minutes before cleanup..."
sleep 300

# 6. Remove Blue version
echo "üßπ Cleaning up Blue version..."
helm uninstall ${RELEASE_NAME}-blue -n $NAMESPACE || true

echo "‚úÖ Blue-Green deployment completed successfully!"
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API —Å–µ—Ä–≤–µ—Ä–∞

#### settings/config.py
```python
from pydantic_settings import BaseSettings
from typing import List, Optional

class Settings(BaseSettings):
    # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    app_name: str = "RAG Platform API"
    environment: str = "production"
    debug: bool = False
    
    # –°–µ—Ä–≤–µ—Ä
    api_host: str = "0.0.0.0"
    api_port: int = 8081
    workers: int = 4
    
    # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    database_url: str
    database_pool_size: int = 20
    database_max_overflow: int = 30
    database_pool_timeout: int = 30
    
    # Redis
    redis_url: str
    redis_ttl: int = 3600
    redis_max_connections: int = 100
    
    # ClickHouse
    clickhouse_url: str
    clickhouse_database: str = "rag_metrics"
    
    # JWT
    jwt_secret_key: str
    jwt_algorithm: str = "HS256"
    jwt_expire_minutes: int = 60
    
    # CORS
    cors_origins: List[str] = ["*"]
    cors_methods: List[str] = ["GET", "POST", "PUT", "DELETE"]
    
    # Rate Limiting
    rate_limit_requests: int = 1000
    rate_limit_window: int = 3600
    
    # File Upload
    upload_max_size: int = 100 * 1024 * 1024  # 100MB
    upload_allowed_extensions: List[str] = [
        ".pdf", ".docx", ".txt", ".html", ".xlsx", ".eml"
    ]
    
    # AI/ML
    ollama_base_url: str = "http://ollama:11434"
    embedding_model: str = "bge-m3"
    llm_model: str = "llama2-7b"
    embedding_dimension: int = 1536
    
    # Logging
    log_level: str = "INFO"
    log_format: str = "json"
    log_file: Optional[str] = None
    
    # Monitoring
    metrics_enabled: bool = True
    prometheus_port: int = 9090
    health_check_interval: int = 30
    
    # Security
    data_encryption_enabled: bool = True
    audit_logging_enabled: bool = True
    session_timeout: int = 3600
    
    class Config:
        env_file = ".env"
        case_sensitive = False
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Nginx

#### nginx.conf
```nginx
upstream api_backend {
    least_conn;
    server api-1:8081 max_fails=3 fail_timeout=30s;
    server api-2:8081 max_fails=3 fail_timeout=30s;
    server api-3:8081 max_fails=3 fail_timeout=30s;
    keepalive 32;
}

upstream streamlit_backend {
    ip_hash;  # –î–ª—è WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    server streamlit-1:8502 max_fails=3 fail_timeout=30s;
    server streamlit-2:8502 max_fails=3 fail_timeout=30s;
    keepalive 16;
}

server {
    listen 80;
    server_name rag-platform.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name rag-platform.com;
    
    # SSL Configuration
    ssl_certificate /etc/ssl/certs/rag-platform.crt;
    ssl_certificate_key /etc/ssl/private/rag-platform.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    # Security Headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
    
    # Rate Limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=upload:10m rate=10r/m;
    
    # Main Application
    location / {
        proxy_pass http://streamlit_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_read_timeout 86400;
    }
    
    # API Endpoints
    location /api/ {
        limit_req zone=api burst=20 nodelay;
        
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    # File Upload (extended timeout)
    location /api/v1/documents/upload {
        limit_req zone=upload burst=5 nodelay;
        
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Extended timeouts for file upload
        proxy_connect_timeout 60s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
        
        # Large file support
        client_max_body_size 100M;
        proxy_request_buffering off;
    }
    
    # Health Check
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    # Static Files
    location /static/ {
        alias /var/www/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PostgreSQL

#### postgresql.conf –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
```sql
-- Performance Settings
shared_buffers = '8GB'                    -- 25% of RAM
effective_cache_size = '24GB'             -- 75% of RAM
work_mem = '256MB'                        -- For complex queries
maintenance_work_mem = '2GB'              -- For maintenance ops
wal_buffers = '64MB'                      -- WAL buffer size

-- Checkpoint Settings
checkpoint_completion_target = 0.9
wal_level = replica
max_wal_size = '4GB'
min_wal_size = '1GB'

-- Connection Settings
max_connections = 200
shared_preload_libraries = 'pg_stat_statements,auto_explain'

-- Logging
log_destination = 'jsonlog'
log_statement = 'mod'
log_min_duration_statement = 1000        -- Log slow queries
auto_explain.log_min_duration = 1000     -- Explain slow queries

-- Vector Extension Settings
shared_preload_libraries = 'vector'
```

#### –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```sql
-- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
CREATE INDEX CONCURRENTLY idx_documents_user_created 
ON documents(user_id, created_at DESC);

CREATE INDEX CONCURRENTLY idx_documents_content_type 
ON documents(content_type) WHERE content_type IS NOT NULL;

CREATE INDEX CONCURRENTLY idx_documents_tags 
ON documents USING GIN(tags);

-- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX CONCURRENTLY idx_chunks_embedding_cosine 
ON document_chunks USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 1000);

-- –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ª–æ–≥–æ–≤
CREATE TABLE audit_logs (
    id BIGSERIAL,
    user_id INTEGER,
    action VARCHAR(50),
    created_at TIMESTAMP DEFAULT NOW(),
    details JSONB
) PARTITION BY RANGE (created_at);

-- –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–π –Ω–∞ –≥–æ–¥ –≤–ø–µ—Ä–µ–¥
DO $$
DECLARE
    start_date DATE := DATE_TRUNC('month', CURRENT_DATE);
    end_date DATE;
BEGIN
    FOR i IN 0..11 LOOP
        end_date := start_date + INTERVAL '1 month';
        EXECUTE format('CREATE TABLE audit_logs_%s PARTITION OF audit_logs 
                       FOR VALUES FROM (%L) TO (%L)',
                       TO_CHAR(start_date, 'YYYY_MM'),
                       start_date,
                       end_date);
        start_date := end_date;
    END LOOP;
END
$$;
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis

#### redis.conf –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
```ini
# Memory Management
maxmemory 8gb
maxmemory-policy allkeys-lru

# Persistence
save 900 1
save 300 10
save 60 10000

# Network
tcp-keepalive 300
timeout 0

# Performance
tcp-backlog 511
databases 16

# Security
requirepass your_secure_redis_password
rename-command FLUSHDB ""
rename-command FLUSHALL ""
rename-command CONFIG "CONFIG_b835556"

# Logging
loglevel notice
logfile /var/log/redis/redis-server.log

# Slow Log
slowlog-log-slower-than 10000
slowlog-max-len 128
```

## üë• –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏

### –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

#### –ß–µ—Ä–µ–∑ API
```python
import requests

# –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
admin_data = {
    "username": "admin_user",
    "email": "admin@company.com",
    "password": "SecureAdminPass123!",
    "full_name": "System Administrator",
    "role": "admin",
    "organization": "IT Department"
}

response = requests.post(
    "https://api.rag-platform.com/api/v1/admin/users",
    headers={"Authorization": "Bearer ADMIN_TOKEN"},
    json=admin_data
)
```

#### –ß–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ —Å—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
docker exec -it rag-platform-api python -c "
from src.services.auth import AuthService
from src.schemas.auth import UserRole

user = AuthService.create_user(
    username='superadmin',
    email='super@company.com',
    password='SuperSecurePass123!',
    full_name='Super Administrator',
    role=UserRole.SUPER_ADMIN
)
print(f'Superuser created: {user.username}')
"
```

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–æ–ª—è–º–∏ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è–º–∏

#### –†–æ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
```python
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π
class UserRole(str, Enum):
    SUPER_ADMIN = "super_admin"  # –ü–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Å–∏—Å—Ç–µ–º–µ
    ADMIN = "admin"              # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
    USER = "user"                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    VIEWER = "viewer"            # –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    READONLY = "readonly"        # –¢–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ
    GUEST = "guest"              # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø

# –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
class Permission(str, Enum):
    READ = "read"
    WRITE = "write"
    DELETE = "delete"
    SHARE = "share"
    ADMIN = "admin"
    USER_MANAGEMENT = "user_mgmt"
    ROLE_MANAGEMENT = "role_mgmt"
    TENANT_SETTINGS = "tenant_settings"
    AUDIT_VIEW = "audit_view"
    METRICS_VIEW = "metrics_view"
    SYSTEM_CONFIG = "system_config"
    API_ACCESS = "api_access"
    BULK_OPERATIONS = "bulk_ops"
    EXPORT_DATA = "export_data"
```

#### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
```python
# –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π
ROLE_PERMISSIONS = {
    UserRole.SUPER_ADMIN: [
        Permission.ADMIN, Permission.USER_MANAGEMENT, 
        Permission.ROLE_MANAGEMENT, Permission.SYSTEM_CONFIG,
        Permission.AUDIT_VIEW, Permission.METRICS_VIEW,
        Permission.READ, Permission.WRITE, Permission.DELETE,
        Permission.SHARE, Permission.API_ACCESS,
        Permission.BULK_OPERATIONS, Permission.EXPORT_DATA
    ],
    UserRole.ADMIN: [
        Permission.USER_MANAGEMENT, Permission.TENANT_SETTINGS,
        Permission.AUDIT_VIEW, Permission.METRICS_VIEW,
        Permission.READ, Permission.WRITE, Permission.DELETE,
        Permission.SHARE, Permission.API_ACCESS,
        Permission.BULK_OPERATIONS, Permission.EXPORT_DATA
    ],
    UserRole.USER: [
        Permission.READ, Permission.WRITE, Permission.SHARE,
        Permission.API_ACCESS, Permission.EXPORT_DATA
    ],
    UserRole.VIEWER: [
        Permission.READ, Permission.API_ACCESS
    ],
    UserRole.READONLY: [
        Permission.READ
    ],
    UserRole.GUEST: [
        Permission.READ  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π
    ]
}
```

### –ú–∞—Å—Å–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

#### –ò–º–ø–æ—Ä—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ CSV
```python
import pandas as pd
import requests

def import_users_from_csv(csv_file_path, admin_token):
    """–ò–º–ø–æ—Ä—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ CSV —Ñ–∞–π–ª–∞"""
    df = pd.read_csv(csv_file_path)
    
    headers = {"Authorization": f"Bearer {admin_token}"}
    url = "https://api.rag-platform.com/api/v1/admin/users"
    
    results = []
    for _, row in df.iterrows():
        user_data = {
            "username": row['username'],
            "email": row['email'],
            "full_name": row['full_name'],
            "role": row.get('role', 'user'),
            "organization": row.get('organization', ''),
            "password": row.get('password', 'TempPass123!')  # –í—Ä–µ–º–µ–Ω–Ω—ã–π –ø–∞—Ä–æ–ª—å
        }
        
        try:
            response = requests.post(url, headers=headers, json=user_data)
            response.raise_for_status()
            results.append({"username": row['username'], "status": "success"})
        except Exception as e:
            results.append({"username": row['username'], "status": f"error: {e}"})
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = import_users_from_csv("users.csv", "ADMIN_TOKEN")
for result in results:
    print(f"{result['username']}: {result['status']}")
```

#### –ú–∞—Å—Å–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π
```bash
# SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
docker exec -it rag-platform-postgres psql -U postgres -d rag_db -c "
UPDATE users 
SET role = 'viewer', updated_at = NOW() 
WHERE organization = 'External Partners' 
  AND role = 'user';
"
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

### Prometheus –º–µ—Ç—Ä–∏–∫–∏

#### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# HTTP –º–µ—Ç—Ä–∏–∫–∏
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code']
)

http_request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

# –ë–∏–∑–Ω–µ—Å –º–µ—Ç—Ä–∏–∫–∏
documents_uploaded_total = Counter(
    'documents_uploaded_total',
    'Total documents uploaded',
    ['user_role', 'content_type']
)

search_queries_total = Counter(
    'search_queries_total', 
    'Total search queries',
    ['search_type', 'user_role']
)

rag_queries_total = Counter(
    'rag_queries_total',
    'Total RAG queries',
    ['model', 'user_role']
)

# –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
active_users = Gauge(
    'active_users_total',
    'Number of active users',
    ['time_window']
)

database_connections = Gauge(
    'database_connections_active',
    'Active database connections',
    ['database']
)

cache_hit_rate = Gauge(
    'cache_hit_rate',
    'Cache hit rate percentage',
    ['cache_type']
)
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Prometheus
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rag_platform_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'rag-platform-api'
    static_configs:
      - targets: ['api:9090']
    metrics_path: /metrics
    scrape_interval: 15s
    scrape_timeout: 10s
    
  - job_name: 'rag-platform-streamlit'
    static_configs:
      - targets: ['streamlit:9091']
    
  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']
    
  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']
    
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

### Grafana –¥–∞—à–±–æ—Ä–¥—ã

#### –î–∞—à–±–æ—Ä–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ API
```json
{
  "dashboard": {
    "title": "RAG Platform API Performance",
    "panels": [
      {
        "title": "HTTP Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time Percentiles",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "99th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status_code=~\"5..\"}[5m]) / rate(http_requests_total[5m]) * 100",
            "legendFormat": "Error Rate %"
          }
        ]
      }
    ]
  }
}
```

### –ê–ª–µ—Ä—Ç—ã –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è

#### –ü—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–æ–≤
```yaml
# rag_platform_rules.yml
groups:
  - name: rag_platform_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}% for the last 5 minutes"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }}s"
      
      - alert: DatabaseConnectionsHigh
        expr: database_connections_active > 150
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High number of database connections"
          description: "Database has {{ $value }} active connections"
      
      - alert: LowCacheHitRate
        expr: cache_hit_rate < 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value }}%"
      
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service is down"
          description: "{{ $labels.job }} has been down for more than 1 minute"
```

#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AlertManager
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.company.com:587'
  smtp_from: 'alerts@rag-platform.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@company.com'
        subject: 'CRITICAL: RAG Platform Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          Description: {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
    slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#critical-alerts'
        title: 'CRITICAL: RAG Platform Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
  
  - name: 'warning-alerts'
    email_configs:
      - to: 'devops@company.com'
        subject: 'WARNING: RAG Platform Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
  
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://webhook-service:5000/alerts'
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

#### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
import structlog
import logging.config

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "json": {
            "()": structlog.stdlib.ProcessorFormatter,
            "processor": structlog.dev.ConsoleRenderer(colors=False),
        },
    },
    "handlers": {
        "default": {
            "level": "INFO",
            "class": "logging.StreamHandler",
            "formatter": "json",
        },
        "file": {
            "level": "INFO",
            "class": "logging.handlers.RotatingFileHandler",
            "filename": "/app/logs/rag-platform.log",
            "maxBytes": 100*1024*1024,  # 100MB
            "backupCount": 10,
            "formatter": "json",
        },
    },
    "loggers": {
        "": {
            "handlers": ["default", "file"],
            "level": "INFO",
            "propagate": True,
        },
    },
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ structlog
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)
```

#### –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å ELK Stack
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /app/logs/*.log
  fields:
    service: rag-platform-api
    environment: production
  fields_under_root: true
  json.keys_under_root: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "rag-platform-%{+yyyy.MM.dd}"

setup.template.name: "rag-platform"
setup.template.pattern: "rag-platform-*"
```

–ü—Ä–æ–¥–æ–ª–∂—É —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...
