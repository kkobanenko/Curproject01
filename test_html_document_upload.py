#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ HTML –¥–æ–∫—É–º–µ–Ω—Ç–∞
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ HTML —Ñ–∞–π–ª–∞
"""

import asyncio
import sys
import logging
from pathlib import Path
import json
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_html_document_processing():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É HTML –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
        import importlib.util
        from pathlib import Path
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º DocumentParser
        spec = importlib.util.spec_from_file_location(
            "document_parser", 
            Path(__file__).parent / "packages" / "rag_core" / "rag_core" / "parsers" / "document_parser.py"
        )
        document_parser_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(document_parser_module)
        DocumentParser = document_parser_module.DocumentParser
        DocumentParserRegistry = document_parser_module.DocumentParserRegistry
        
        # –°–æ–∑–¥–∞–µ–º HTML –ø–∞—Ä—Å–µ—Ä
        class HTMLParser(DocumentParser):
            def __init__(self):
                super().__init__()
                self.supported_mime_types = ['text/html']
            
            def can_parse(self, file_path: Path) -> bool:
                return (file_path.suffix.lower() in ['.html', '.htm'] and 
                        file_path.exists())
            
            def parse(self, file_path: Path):
                from bs4 import BeautifulSoup
                import hashlib
                
                # –í—ã—á–∏—Å–ª—è–µ–º SHA256
                sha256_hash = hashlib.sha256()
                with open(file_path, "rb") as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        sha256_hash.update(chunk)
                sha256 = sha256_hash.hexdigest()
                
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                    html_content = file.read()
                
                # –ü–∞—Ä—Å–∏–º —Å BeautifulSoup
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {}
                title_tag = soup.find('title')
                if title_tag:
                    metadata['title'] = title_tag.get_text().strip()
                
                # –£–±–∏—Ä–∞–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
                for script in soup(["script", "style", "noscript"]):
                    script.decompose()
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                text_sections = []
                for heading in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
                    text_sections.append(heading.get_text().strip())
                
                for paragraph in soup.find_all('p'):
                    text = paragraph.get_text().strip()
                    if text:
                        text_sections.append(text)
                
                full_text = '\n\n'.join(text_sections)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
                tables = []
                for table_index, table in enumerate(soup.find_all('table')):
                    table_data = []
                    rows = table.find_all('tr')
                    for row in rows:
                        row_data = []
                        cells = row.find_all(['td', 'th'])
                        for cell in cells:
                            cell_text = cell.get_text(strip=True)
                            row_data.append(cell_text)
                        if row_data:
                            table_data.append(row_data)
                    
                    if table_data:
                        table_info = {
                            'table_index': table_index,
                            'data': table_data,
                            'rows': len(table_data),
                            'cols': len(table_data[0]) if table_data else 0
                        }
                        tables.append(table_info)
                
                # –°—á–∏—Ç–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                links_count = len(soup.find_all('a'))
                images_count = len(soup.find_all('img'))
                
                return {
                    'title': metadata.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'),
                    'text': full_text,
                    'tables': tables,
                    'pages': [{'page_num': 1, 'text': full_text[:1000] + '...'}],
                    'sha256': sha256,
                    'mime_type': 'text/html',
                    'needs_ocr': False,
                    'metadata': metadata,
                    'table_count': len(tables),
                    'has_tables': len(tables) > 0,
                    'links_count': links_count,
                    'images_count': images_count
                }
        
        # –°–æ–∑–¥–∞–µ–º registry –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä
        registry = DocumentParserRegistry()
        html_parser = HTMLParser()
        registry.register(html_parser)
        
        # –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
        html_file = Path("data/inbox/–°–º–∏—Ä—è–≥–∏–Ω –ê–Ω–¥—Ä–µ–π. –ê–ø–ø–µ—Ç–∏—Ç–Ω—ã–π –ø—Ä—ã—â–∏–∫ - royallib.ru.html")
        
        if not html_file.exists():
            logger.error(f"HTML —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {html_file}")
            return False
        
        logger.info(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HTML –¥–æ–∫—É–º–µ–Ω—Ç: {html_file}")
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–∞—Ä—Å–µ—Ä
        parser = registry.get_parser(html_file)
        if not parser:
            logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Ñ–∞–π–ª–∞: {html_file}")
            return False
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–∞—Ä—Å–µ—Ä: {parser.__class__.__name__}")
        
        # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
        result = parser.parse(html_file)
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        document_info = {
            'id': f"doc_{result['sha256'][:8]}",
            'title': result.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'),
            'source_path': str(html_file),
            'mime_type': result.get('mime_type', 'text/html'),
            'sha256': result.get('sha256', ''),
            'size_bytes': html_file.stat().st_size,
            'tenant_id': 'default',
            'created_at': datetime.utcnow().isoformat(),
            'metadata': {
                'description': 'HTML –¥–æ–∫—É–º–µ–Ω—Ç —Å –∫–Ω–∏–≥–æ–π',
                'tags': ['–∫–Ω–∏–≥–∞', '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'html'],
                'original_filename': html_file.name,
                'processing_info': {
                    'parser': parser.__class__.__name__,
                    'processed_at': datetime.utcnow().isoformat(),
                    'text_length': len(result.get('text', '')),
                    'tables_count': result.get('table_count', 0),
                    'links_count': result.get('links_count', 0),
                    'images_count': result.get('images_count', 0)
                }
            },
            'chunk_count': 0,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ—Å–ª–µ —á–∞–Ω–∫–∏–Ω–≥–∞
            'status': 'processed'
        }
        
        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        logger.info(f"   - Document ID: {document_info['id']}")
        logger.info(f"   - –ó–∞–≥–æ–ª–æ–≤–æ–∫: {document_info['title']}")
        logger.info(f"   - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {document_info['size_bytes']} –±–∞–π—Ç")
        logger.info(f"   - –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(result.get('text', ''))}")
        logger.info(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü: {result.get('table_count', 0)}")
        logger.info(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫: {result.get('links_count', 0)}")
        logger.info(f"   - SHA256: {result.get('sha256', '')[:16]}...")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
        text = result.get('text', '')
        if text:
            logger.info(f"   - –ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞: {text[:300]}...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–∞–π–ª
        output_file = Path("data/processed_html_document.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'document_info': document_info,
                'parsed_content': result,
                'processing_timestamp': datetime.utcnow().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_document_validation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        output_file = Path("data/processed_html_document.json")
        
        if not output_file.exists():
            logger.error(f"–§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω: {output_file}")
            return False
        
        logger.info(f"üîç –í–∞–ª–∏–¥–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {output_file}")
        
        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        with open(output_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        document_info = data.get('document_info', {})
        parsed_content = data.get('parsed_content', {})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        required_fields = ['id', 'title', 'source_path', 'mime_type', 'sha256', 'size_bytes']
        for field in required_fields:
            if field not in document_info:
                logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º SHA256
        if len(document_info['sha256']) != 64:
            logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç SHA256: {document_info['sha256']}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if document_info['size_bytes'] <= 0:
            logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {document_info['size_bytes']}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º MIME —Ç–∏–ø
        if document_info['mime_type'] != 'text/html':
            logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π MIME —Ç–∏–ø: {document_info['mime_type']}")
            return False
        
        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        logger.info(f"   - –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        logger.info(f"   - SHA256 –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
        logger.info(f"   - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {document_info['size_bytes']} –±–∞–π—Ç")
        logger.info(f"   - MIME —Ç–∏–ø: {document_info['mime_type']}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üß™ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ HTML –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    
    tests = [
        ("HTML Document Processing", test_html_document_processing),
        ("Document Validation", test_document_validation),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logger.info(f"\n--- –¢–µ—Å—Ç–∏—Ä—É–µ–º {test_name} ---")
        if test_func():
            passed += 1
            logger.info(f"‚úÖ {test_name} –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error(f"‚ùå {test_name} –Ω–µ –ø—Ä–æ—à–µ–ª")
    
    logger.info(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—à–ª–∏")
    
    if passed == total:
        logger.info("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        logger.info("‚úÖ HTML –¥–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –≤ —Å–∏—Å—Ç–µ–º—É")
        logger.info("üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ data/processed_html_document.json")
        return 0
    else:
        logger.error("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏")
        return 1

if __name__ == "__main__":
    sys.exit(main())
